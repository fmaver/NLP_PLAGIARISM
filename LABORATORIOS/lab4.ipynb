{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# LAB 4\n",
    "## Semántica Léxica (Lexical Semantics)\n",
    "\n",
    "Este laboratorio se centra en la semántica léxica y utiliza NLTK para brindarte experiencia práctica con WordNet y realizar la desambiguación del sentido de las palabras.  El ejercicio se basa en tutoriales en el sitio web de NLTK "
   ],
   "id": "f1493c771b39bc14"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### NLTK Library\n",
    "If you have not installed the NLTK library, you can do so by running the following command in the teriminal:\n",
    "```bash\n",
    "poetry add nltk\n",
    "```"
   ],
   "id": "7b438c6e07bdd2b9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-08T21:10:13.319062Z",
     "start_time": "2024-06-08T21:10:13.316451Z"
    }
   },
   "source": [
    "import nltk\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "nltk.download()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:11:30.573660Z",
     "start_time": "2024-06-08T21:11:25.811285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.book import *\n",
    "from nltk.corpus import wordnet as wn"
   ],
   "id": "49831a38ae03cf7b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "WordNet\testá\torganizado\tcomo\tsynsets,\tcada\tsynset\tes\tun\tconjunto\tde\tpalabras\tsinónimas.\tUna\tpalabra\taparecerá\ten\tmúltiples\tsynsets\tsi\ttiene\tmúltiples\tsentidos(senses),\tasí\tcomo\tsi\tpuede\taparecer\ten\tmás\tde\tun\tPOS.\t\tPor\tejemplo:\tsustantivo\ty\tverbo.\tPodes\trecuperar\ttodos\tlos\tsynsets\tasociados\tcon\tuna\tpalabra\tusando\tla\tllamada\tal\tmétodo\tsynsets():\t\t",
   "id": "5ac0f804f4494cd7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:37:48.669529Z",
     "start_time": "2024-06-08T21:37:48.665867Z"
    }
   },
   "cell_type": "code",
   "source": [
    "wn.synsets('dog')\n",
    "\n",
    "# Vemos\tque\thay\t7\tsynsets\tde\tsustantivos\ty\t1\tsynset\tde\tverbos\tasociados\tcon\tla\tpalabra\t\"perro\".\tPuede\trestringir\tla\trecuperación\ta\tun\tPOS\tparticular\tutilizando\tel\targumento\tpos.  "
   ],
   "id": "13911784e2bb317e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:12:13.171148Z",
     "start_time": "2024-06-08T21:12:13.167423Z"
    }
   },
   "cell_type": "code",
   "source": "wn.synsets('dog', pos=wn.VERB)",
   "id": "892329b7f7f2361b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "En la salida anterior, el segundo synset se conoce como frump.n.01. Este synset es el mismo que dog.n.02. frump.n.01 solo significa que este synset es también el primer synset para la palabra \"frump\". Pruebe lo siguiente para comprender mejor: ",
   "id": "f3a35fb746c468d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:13:53.152357Z",
     "start_time": "2024-06-08T21:13:53.149818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(wn.synset('dog.n.01'))\n",
    "print(wn.synset('dog.n.02'))\n",
    "print(wn.synset('frump.n.01'))"
   ],
   "id": "4f4afde069adb2a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('dog.n.01')\n",
      "Synset('frump.n.01')\n",
      "Synset('frump.n.01')\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:14:47.914969Z",
     "start_time": "2024-06-08T21:14:47.912683Z"
    }
   },
   "cell_type": "code",
   "source": "print(wn.synset('dog.n.01').definition())",
   "id": "877d16bc6c60502e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:14:54.725808Z",
     "start_time": "2024-06-08T21:14:54.723019Z"
    }
   },
   "cell_type": "code",
   "source": "print(wn.synset('dog.n.02').definition())",
   "id": "8c495c716517c2c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a dull unattractive unpleasant girl or woman\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Hay\ttres\tsinónomos\tpara\tel\tsynset\tde\t‘dog’:\t‘dog’,\t‘domestic\tdog’\ty\t‘Canis\tfamiliaris’.\tEstos\taparecen\ten\tel\touput\tde\tla\túltima\tinstrucción.\t",
   "id": "e1066f777e4ebee9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:15:17.778872Z",
     "start_time": "2024-06-08T21:15:17.775941Z"
    }
   },
   "cell_type": "code",
   "source": "print(wn.synset('dog.n.01').lemmas())",
   "id": "33b4565f11953b87",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('dog.n.01.dog'), Lemma('dog.n.01.domestic_dog'), Lemma('dog.n.01.Canis_familiaris')]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:26:54.215372Z",
     "start_time": "2024-06-08T21:26:54.212176Z"
    }
   },
   "cell_type": "code",
   "source": "print(wn.synset('dog.n.02').lemmas())",
   "id": "eca8863bf2cd3e19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('frump.n.01.frump'), Lemma('frump.n.01.dog')]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Ahora veamos cómo consultar las relaciones entre los synsets de WordNet. Recuerde que el hiperónimo se refiere al superconjunto de una entidad y el hipónimo se refiere a subconjuntos más específicos.  ",
   "id": "a953f134772d0b54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:27:32.761227Z",
     "start_time": "2024-06-08T21:27:32.758877Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dog = wn.synset('dog.n.01')\n",
    "print(dog.hypernyms())"
   ],
   "id": "3efc29122e46f3f9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('canine.n.02'), Synset('domestic_animal.n.01')]\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:27:42.695450Z",
     "start_time": "2024-06-08T21:27:42.692513Z"
    }
   },
   "cell_type": "code",
   "source": "print(dog.hyponyms())",
   "id": "8b7f07aee9a5a1c2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('basenji.n.01'), Synset('corgi.n.01'), Synset('cur.n.01'), Synset('dalmatian.n.02'), Synset('great_pyrenees.n.01'), Synset('griffon.n.02'), Synset('hunting_dog.n.01'), Synset('lapdog.n.01'), Synset('leonberg.n.01'), Synset('mexican_hairless.n.01'), Synset('newfoundland.n.01'), Synset('pooch.n.01'), Synset('poodle.n.01'), Synset('pug.n.01'), Synset('puppy.n.01'), Synset('spitz.n.01'), Synset('toy_dog.n.01'), Synset('working_dog.n.01')]\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Como ya vimos en la sección anterior, las formas de palabras individuales en un conjunto se conocen como lemas. Algunas relaciones solo se mantienen entre lemas (es decir, entre formas de palabras específicas) en lugar de los conjuntos de sinónimos.",
   "id": "ce3a01e70c0bd445"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:28:29.583057Z",
     "start_time": "2024-06-08T21:28:29.580488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "good = wn.synset('good.a.01')\n",
    "print(good.lemmas())"
   ],
   "id": "840b9a9aeb64475",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lemma('good.a.01.good')]\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Solo\thay\tuna\tforma\tde\tlema\to\tpalabra\ten\teste\tsintetizador.\tPuede\trecuperar\tantónimos\tpara\tuna\tforma\tde\tpalabra\tde\tla\tsiguiente\tmanera:\t",
   "id": "7adce95bd5d85e49"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:28:54.859018Z",
     "start_time": "2024-06-08T21:28:54.856183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "g0 = good.lemmas()[0]\n",
    "g0.antonyms()"
   ],
   "id": "d990d95fe9af3451",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('bad.a.01.bad')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Exploremos también dos relaciones más: meronym y holonym. \n",
    "* Un merónimo de una palabra es una subparte o miembro. \n",
    "* Un holónimo es un todo del cual la palabra es parte o miembro. \n",
    "\n",
    "Hay métodos separados en NLTK que recuperan merónimos / holónimos para las relaciones entre partes y miembros. P.ej: "
   ],
   "id": "ffc5fca0561801b6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:30:09.986309Z",
     "start_time": "2024-06-08T21:30:09.982881Z"
    }
   },
   "cell_type": "code",
   "source": "dog.part_meronyms()",
   "id": "1fb4a893d2d515c4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('flag.n.07')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:30:39.836053Z",
     "start_time": "2024-06-08T21:30:39.832649Z"
    }
   },
   "cell_type": "code",
   "source": "dog.member_meronyms()",
   "id": "a9860281f477ce69",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:30:57.712931Z",
     "start_time": "2024-06-08T21:30:57.709643Z"
    }
   },
   "cell_type": "code",
   "source": "dog.part_holonyms()",
   "id": "d2e39adf8fa20b38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:31:01.871849Z",
     "start_time": "2024-06-08T21:31:01.868270Z"
    }
   },
   "cell_type": "code",
   "source": "dog.member_holonyms()",
   "id": "cf463f8d32228629",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('canis.n.01'), Synset('pack.n.06')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Este resultado dice que flag.n.07 es parte de dog.n.01 y dog.n.01 es miembro de canis.n.01 y pack.n.06. ",
   "id": "dee343a150e2b4c0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Utilizando lo que ha estudiado hasta ahora, imprima las definiciones de flag.n.07, canis.n.01 y pack.n.06 y vea si ve por qué estos synsets están relacionados de esta manera",
   "id": "832736214ef88589"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:31:59.064590Z",
     "start_time": "2024-06-08T21:31:59.061447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(wn.synset('flag.n.07').definition())\n",
    "print(wn.synset('canis.n.01').definition())\n",
    "print(wn.synset('pack.n.06').definition())"
   ],
   "id": "c1a9428289f9f15a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a conspicuously marked or shaped tail\n",
      "type genus of the Canidae: domestic and wild dogs; wolves; jackals\n",
      "a group of hunting animals\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Desambiguación de palabras por sentido (Word Sense Desambiguation)",
   "id": "d02646db62a43455"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Como vimos en las clases, la tarea de desambiguación del sentido de las palabras es tomar una palabra en el contexto de la oración y mapearla a uno de los sentidos de la palabra, por ejemplo. asignar a un synset en WordNet. \n",
    "\n",
    "Estudiamos dos enfoques, un sistema de clasificación supervisado donde las palabras de contexto entran como feautres(características) y el otro es el algoritmo de Lesk que utilizó el recurso del diccionario para la desambiguación. "
   ],
   "id": "2cc7d023e8e9ceb1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:38:16.135440Z",
     "start_time": "2024-06-08T21:38:16.131222Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ¿Cuántos sentidos crees que tiene la palabra bank?\n",
    "wn.synsets('bank')"
   ],
   "id": "7860cdb2f1b48810",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10'),\n",
       " Synset('bank.v.01'),\n",
       " Synset('bank.v.02'),\n",
       " Synset('bank.v.03'),\n",
       " Synset('bank.v.04'),\n",
       " Synset('bank.v.05'),\n",
       " Synset('deposit.v.02'),\n",
       " Synset('bank.v.07'),\n",
       " Synset('trust.v.01')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:33:21.783738Z",
     "start_time": "2024-06-08T21:33:21.780747Z"
    }
   },
   "cell_type": "code",
   "source": "wn.synsets('bank', pos=wn.NOUN)",
   "id": "5f58379047de1a4b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('bank.n.01'),\n",
       " Synset('depository_financial_institution.n.01'),\n",
       " Synset('bank.n.03'),\n",
       " Synset('bank.n.04'),\n",
       " Synset('bank.n.05'),\n",
       " Synset('bank.n.06'),\n",
       " Synset('bank.n.07'),\n",
       " Synset('savings_bank.n.02'),\n",
       " Synset('bank.n.09'),\n",
       " Synset('bank.n.10')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:39:10.085682Z",
     "start_time": "2024-06-08T21:39:10.082543Z"
    }
   },
   "cell_type": "code",
   "source": "sentence = \"The bank can guarantee deposits will eventually cover future tuition costs because it invests in adjustable-rate mortgage securities.\"",
   "id": "2872ecaac8f8388e",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:39:10.923605Z",
     "start_time": "2024-06-08T21:39:10.920838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ¿Qué synset es el sentido correcto para la palabra en el contexto de la oración anterior? \n",
    "# Vamos a usar el algoritmo de wn lesk para averiguarlo\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "ambiguous = 'bank'\n",
    "lesk_sense = lesk(sentence.split(), ambiguous)\n",
    "print(lesk_sense, lesk_sense.definition())"
   ],
   "id": "23e352f7eb97cad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('bank.n.05') a supply or stock held in reserve for future use (especially in emergencies)\n"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ejercicio: para cada ejemplo, a continuación descubra el sentido correcto de WordNet según su criterio",
   "id": "2954d29b18e629ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:43:25.702812Z",
     "start_time": "2024-06-08T21:43:25.698215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence1 = \"I went to the bank to deposit my money\"\n",
    "ambiguous1 = 'bank'\n",
    "\n",
    "sentence2 = \"She created a big mess of the birthday cake\"\n",
    "ambiguous2 = 'mess'\n",
    "\n",
    "sentence3 = \"In the interest of your safety, please wear your seatbelt\"\n",
    "ambiguous3 = 'interest'\n",
    "\n",
    "sentence4 = \"I drank some ice cold water\"\n",
    "ambiguous4 = 'cold'\n",
    "\n",
    "\n",
    "lesk_sense1 = lesk(sentence1.split(), ambiguous1)\n",
    "lesk_sense2 = lesk(sentence2.split(), ambiguous2)\n",
    "lesk_sense3 = lesk(sentence3.split(), ambiguous3)\n",
    "lesk_sense4 = lesk(sentence4.split(), ambiguous4)\n",
    "\n",
    "#print the sentence, the ambiguous word and the sense with correct identation and format\n",
    "for i, sense in enumerate([lesk_sense1, lesk_sense2, lesk_sense3, lesk_sense4]):\n",
    "    print(f\"Sentence {i+1}:\")\n",
    "    print(f\"  {sentence1 if i == 0 else sentence2 if i == 1 else sentence3 if i == 2 else sentence4}\")\n",
    "    print(f\"  Ambiguous word: {ambiguous1 if i == 0 else ambiguous2 if i == 1 else ambiguous3 if i == 2 else ambiguous4}\")\n",
    "    print(f\"  Sense: {sense.definition()}\")\n",
    "    print()"
   ],
   "id": "908541c8a4f4aef6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "  I went to the bank to deposit my money\n",
      "  Ambiguous word: bank\n",
      "  Sense: a container (usually with a slot in the top) for keeping money at home\n",
      "\n",
      "Sentence 2:\n",
      "  She created a big mess of the birthday cake\n",
      "  Ambiguous word: mess\n",
      "  Sense: make a mess of or create disorder in\n",
      "\n",
      "Sentence 3:\n",
      "  In the interest of your safety, please wear your seatbelt\n",
      "  Ambiguous word: interest\n",
      "  Sense: excite the curiosity of; engage the interest of\n",
      "\n",
      "Sentence 4:\n",
      "  I drank some ice cold water\n",
      "  Ambiguous word: cold\n",
      "  Sense: having a low or inadequate temperature or feeling a sensation of coldness or having been made cold by e.g. ice or refrigeration\n",
      "\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Un poco mas alla\n",
    "Si ya estás cómodo con el contenido anterior, podés desafiarte con este ejercicio. Este ejercicio tiene un “final abierto”. \n",
    "\n",
    "Ejercicio: un lemma de una palabra agrupa las inflexiones de una palabra. Es decir, ‘walked’, ‘walking’, ‘walks’, ‘walk’ son todas inflexiones o variantes morfológicas de la palabra walk (\"caminar\"). NLTK tiene capacidad para lematizar palabras. "
   ],
   "id": "ed7f065c5de0a13e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:53:09.261107Z",
     "start_time": "2024-06-08T21:53:09.258002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "wnl = WordNetLemmatizer()\n",
    "print(wnl.lemmatize('dogs', 'n'))\n",
    "print(wnl.lemmatize('walking', 'v'))"
   ],
   "id": "450aea1bd2251c29",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n",
      "walk\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Aquí informamos al lematizador si la palabra dada es un sustantivo o un verbo. La configuración predeterminada para el método es un sustantivo, es decir. si corre sin argumentos, el lema será correcto para los sustantivos pero quizás no para los verbos. ",
   "id": "5b378b85d19643b0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:45:52.324316Z",
     "start_time": "2024-06-08T21:45:52.321810Z"
    }
   },
   "cell_type": "code",
   "source": "print(wnl.lemmatize('dogs'))",
   "id": "ff1c66d6458c7606",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#¿Podrías mejorar el algoritmo de Lesk con un lematizador? Si es así, ¿podrías escribir una función de match, que tome dos cadenas y devuelva las palabras coincidentes entre ellas? Queremos que las coincidencias(matches) sean útiles para un algoritmo como Lesk. ¿Quizás también necesites usar un etiquetador POS? Podes usar un etiquetador POS incorporado en WordNet. \n",
    "\n",
    "# nltk.pos\ttag(word\ttokenize(\"I\twent\tto\tthe\tbank\tto\tdeposit\tsome\tmoney.\"))\t[(’I’,\t’PRP’),\t(’went’,\t’VBD’),\t(’to’,\t’TO’),\t(’the’,\t’DT’),\t(’bank’,\t’NN’),\t(’to’,\t’TO’),\t(’deposit’,\t’VB’),\t(’some’,\t’DT’),\t(’money’,\t’NN’),\t(’.’,\t’.’)]\t \n"
   ],
   "id": "87548beb6e00f9fb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:48:22.826483Z",
     "start_time": "2024-06-08T21:48:22.823330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import pos_tag, word_tokenize\n",
    "\n",
    "\n",
    "def match(s1, s2):\n",
    "    # Tokenize the sentences\n",
    "    s1_tokens = word_tokenize(s1)\n",
    "    s2_tokens = word_tokenize(s2)\n",
    "    \n",
    "    # POS tag the tokens\n",
    "    s1_pos = pos_tag(s1_tokens)\n",
    "    s2_pos = pos_tag(s2_tokens)\n",
    "    \n",
    "    # Lemmatize the tokens\n",
    "    wnl2 = WordNetLemmatizer()\n",
    "    s1_lemmas = [wnl2.lemmatize(token, pos) for token, pos in s1_pos]\n",
    "    s2_lemmas = [wnl2.lemmatize(token, pos) for token, pos in s2_pos]\n",
    "    \n",
    "    # Return the intersection of the lemmatized tokens\n",
    "    return set(s1_lemmas).intersection(set(s2_lemmas))"
   ],
   "id": "7d94e11e730e5d25",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T21:49:36.976041Z",
     "start_time": "2024-06-08T21:49:36.974081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the match function\n",
    "s1 = \"I went to the bank to deposit some money.\"\n",
    "s2 = \"I went to the river bank to see the sunset.\"\n",
    "#print(match(s1, s2))"
   ],
   "id": "140abc236ddb9404",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:02:34.130776Z",
     "start_time": "2024-06-08T22:02:34.126543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Función de lematización con POS tagging\n",
    "def lemmatize_sentence(sentence):\n",
    "    import re\n",
    "    wnl = WordNetLemmatizer()\n",
    "    lemmatized_sentence = []\n",
    "    token_sentence = [word for word in word_tokenize(sentence.lower()) if re.search(\"\\w\", word)]\n",
    "    pos_tagged = pos_tag(token_sentence)\n",
    "    for word, tag in pos_tagged:\n",
    "        wordnet_tag = get_wordnet_pos(tag) or wordnet.NOUN\n",
    "        lemmatized_word = wnl.lemmatize(word, pos=wordnet_tag)\n",
    "        lemmatized_sentence.append(lemmatized_word)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "# Función para encontrar coincidencias entre dos cadenas\n",
    "def match(sentence1, sentence2):\n",
    "    lemmatized_sentence1 = lemmatize_sentence(sentence1)\n",
    "    lemmatized_sentence2 = lemmatize_sentence(sentence2)\n",
    "    matches = set(lemmatized_sentence1).intersection(set(lemmatized_sentence2))\n",
    "    return matches"
   ],
   "id": "b70eae8fcf315f2a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "<>:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "/var/folders/n7/q7zcbzwd06x1qywn2j98x0y40000gn/T/ipykernel_5153/195583803.py:18: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  token_sentence = [word for word in word_tokenize(sentence.lower()) if re.search(\"\\w\", word)]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:02:36.503702Z",
     "start_time": "2024-06-08T22:02:36.499630Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence1 = \"The striped bats are hanging on their feet for best\"\n",
    "sentence2 = \"Bats can see using echolocation and they hang upside down\"\n",
    "\n",
    "matches = match(sentence1, sentence2)\n",
    "print(\"Palabras coincidentes:\", matches)"
   ],
   "id": "5ef9b16767a5663e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras coincidentes: {'hang', 'bat'}\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-08T22:03:08.320211Z",
     "start_time": "2024-06-08T22:03:08.315267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "s1 = \"I went to the bank to deposit some money.\"\n",
    "s2 = \"I went to the river bank to see the sunset.\"\n",
    "print(match(s1, s2))"
   ],
   "id": "92f740394370555f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bank', 'to', 'the', 'i', 'go'}\n"
     ]
    }
   ],
   "execution_count": 57
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbc166f0453a9f67"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
