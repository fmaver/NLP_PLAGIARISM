{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "1. Chequear si tiene el nombre en el archivo\n",
    "2. Si no lo tiene, chequear que este el nombre en las primeras 50 palabras\n",
    "3. Si aparece mas de un nombre eliminar el nombre de profesores conocidos: Hernan Borre y Alejandro Prince \n",
    "4. eliminar sustantivos de los nombres (ej: \"legajo\", \"alumno\", \"estudiante\")\n",
    "5. Si aun asi no aparece el nombre, setearlo a \"Unknown\""
   ],
   "id": "d8d03f61ca021042"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Para Encontrar Donde hubo plagio\n",
    "cuando elasticsearch me devuelva los posibles plagios, chequeo manual con spacy, que rompe sentencia a sentencia y chequee con cosine similarity si fue en esa sentencia donde hubo plagio."
   ],
   "id": "670a258c0f7faa1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:03:36.669422Z",
     "start_time": "2024-05-21T00:03:34.192009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"es_core_news_lg\")"
   ],
   "id": "7cfb13b20941b143",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:24:13.107221Z",
     "start_time": "2024-05-21T00:24:13.101573Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from itertools import dropwhile\n",
    "\n",
    "def _find_out_author(page_text: str) -> str:\n",
    "        \"\"\"\n",
    "        Finds out the author of the assignment.\n",
    "        It supposes that the document contains a page with the author's name on it.\n",
    "\n",
    "        Args:\n",
    "            page_text: The first page of the assignment.\n",
    "\n",
    "        Returns:\n",
    "            str: The author's name.\n",
    "        \"\"\"\n",
    "        words_to_remove = [\"LEGAJO\", \"ALUMNO\", \"ESTUDIANTE\", \"FECHA\", \"AYUDANTE\", \"SISTEMAS\", \"CARRERA\", \"ALUMNA\", \"EXPLIQUE\", \".TXT\"]\n",
    "        excluded_names = [\n",
    "                \"Dr\",\n",
    "                \"Ingeniero\",\n",
    "                \"Ing\",\n",
    "                \"Licenciado\",\n",
    "                \"Lic\",\n",
    "                \"MSc\",\n",
    "                \"Mg\",\n",
    "                \"Profesor\",\n",
    "                \"Prof\",\n",
    "                \"Borré\",\n",
    "                \"Borre\",\n",
    "                \"Hernán Borré\",\n",
    "                \"Hernan Borré\",\n",
    "                \"Hernán Borre\",\n",
    "                \"Hernan Borre\",\n",
    "                \"Maximiliano Bracho\",\n",
    "                \"Alejandro Bracho\",\n",
    "                \"Alejandro Prince\",\n",
    "                \"Prince\",\n",
    "                \"Anderson\",]\n",
    "    \n",
    "        page_text = page_text.replace(\"\\n\", \" \")\n",
    "\n",
    "        doc = nlp(page_text)\n",
    "\n",
    "        names = [\n",
    "            ent.text.title()\n",
    "            for ent in doc.ents\n",
    "            if (ent.label_ == \"PER\" and not any(name in ent.text for name in excluded_names))\n",
    "        ]\n",
    "\n",
    "        possible_name = next(dropwhile(lambda name: name == \"UNKNOWN_AUTHOR\", names), None)\n",
    "\n",
    "        if not possible_name:\n",
    "            return \"UNKNOWN_AUTHOR\"\n",
    "\n",
    "        for noun in words_to_remove:\n",
    "            possible_name = possible_name.upper().replace(noun, \"\").title()\n",
    "\n",
    "        return possible_name.strip()"
   ],
   "id": "ae1537c35eed777f",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CASO 1",
   "id": "524c6ea75c6323b1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:11:11.723357Z",
     "start_time": "2024-05-20T00:11:11.702576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/K5071 - Matias David Choren - TP N6 Sistemas Emergentes (1).txt\"\n",
    "_find_out_author(txt_path)"
   ],
   "id": "e9810625e65e7702",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Matias David Choren'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 79
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CASO 2",
   "id": "c5ad2e4cc34bcf30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:11:12.861130Z",
     "start_time": "2024-05-20T00:11:12.833098Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_2 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/Marketing - TP 0.txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_2))\n",
    "\n",
    "with open(txt_path_2, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))"
   ],
   "id": "b11bfdc52696d161",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "Ivo Ursino\n"
     ]
    }
   ],
   "execution_count": 80
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### CASO 3",
   "id": "41fbcd937195c58e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-20T00:11:14.364048Z",
     "start_time": "2024-05-20T00:11:14.332528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_3 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/TP Larga Cola.txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_3))\n",
    "\n",
    "with open(txt_path_3, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))"
   ],
   "id": "dace51959bb274c1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "Hernán Suzuki Son\n"
     ]
    }
   ],
   "execution_count": 81
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:32:36.350931Z",
     "start_time": "2024-05-21T00:32:36.318544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_3 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/Mkt_JourdanMartin_Tp1.txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_3))\n",
    "\n",
    "with open(txt_path_3, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))"
   ],
   "id": "4c41cad102b2cb0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:33:16.490232Z",
     "start_time": "2024-05-21T00:33:16.444715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_3 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/TP 2 - La economía Long Tail.txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_3))\n",
    "\n",
    "with open(txt_path_3, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))\n",
    "    if not _find_out_author(text).strip():\n",
    "        print(\"UNKNOWN_AUTHOR\")"
   ],
   "id": "8774b765f2ad665f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "UNKNOWN_AUTHOR\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:31:05.366495Z",
     "start_time": "2024-05-21T00:31:05.331258Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_3 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/TP4 (1).txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_3))\n",
    "\n",
    "with open(txt_path_3, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))"
   ],
   "id": "a7cf842fe0afc758",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T00:40:04.017477Z",
     "start_time": "2024-05-21T00:40:03.981920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "txt_path_3 = \"/Users/franciscomaver/PycharmProjects/NLP_PLAGIARISM/data_txt/files/TP1 - Larga cola.txt\"\n",
    "\n",
    "print(_find_out_author(txt_path_3))\n",
    "\n",
    "with open(txt_path_3, 'r') as file:\n",
    "    text = file.read().replace('\\n', ' ')\n",
    "    text = ' '.join(text.split()[:50])\n",
    "    print(_find_out_author(text))"
   ],
   "id": "7f1181506d654d0c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN_AUTHOR\n",
      "UNKNOWN_AUTHOR\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c979622a298ecbdc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
